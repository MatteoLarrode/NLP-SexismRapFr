{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27166c2a",
   "metadata": {},
   "source": [
    "# French rap word embeddings training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d06d8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94279c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from utils.training_helpers import train_word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d593d18",
   "metadata": {},
   "source": [
    "Code inspired from Schmahl, K. G., Viering, T., Makrodimitris, S., Jahfari, A. N., Tax, D., & Loog, M. (2020). Is Wikipedia succeeding in reducing gender bias? Assessing changes in gender bias in Wikipedia using word embeddings. NLPCSS. https://doi.org/10.18653/V1/2020.NLPCSS-1.11\n",
    "\n",
    "https://gitlab.com/kschmahl/wikipedia-gender-bias-over-time/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corpus\n",
    "with open(\"../data/processed_lyrics.pkl\", \"rb\") as f:\n",
    "    corpus = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../models'\n",
    "\n",
    "# Fixed training parameters\n",
    "fixed_params = {\n",
    "    'epochs': 5,\n",
    "    'workers': 4,\n",
    "    'seed': 35\n",
    "}\n",
    "\n",
    "# Window size of 5 consistently performed best in validation metrics\n",
    "model_configs = [\n",
    "    {'vector_size': 100, 'window': 5, 'min_count': 5,   'sg': 1},\n",
    "    {'vector_size': 200, 'window': 5, 'min_count': 5,  'sg': 1},\n",
    "    {'vector_size': 100, 'window': 5, 'min_count': 5,  'sg': 0},\n",
    "    {'vector_size': 200, 'window': 5, 'min_count': 5, 'sg': 0},\n",
    "]\n",
    "\n",
    "# Train each model\n",
    "for i, config in enumerate(model_configs, 1):\n",
    "    vector_size = config['vector_size']\n",
    "    min_count = config['min_count']\n",
    "    window = config['window']\n",
    "    sg = config['sg']\n",
    "    algo = 'skipgram' if sg == 1 else 'cbow'\n",
    "    lemmatized = config.get('lemmatized', False)\n",
    "\n",
    "    print(f\"Training model {i}/{len(model_configs)} | {algo}, dim={vector_size}, min_count={min_count}, window = {window}, lemmatized={lemmatized}\")\n",
    "\n",
    "    # Merge parameters\n",
    "    train_params = {\n",
    "        'vector_size': vector_size,\n",
    "        'min_count': min_count,\n",
    "        'window': window,\n",
    "        'sg': sg,\n",
    "        'lemmatized': lemmatized,\n",
    "        **fixed_params\n",
    "    }\n",
    "\n",
    "    # Train the model (if gets saved automatically to a subdirectory)\n",
    "    model = train_word2vec(\n",
    "        corpus=corpus,\n",
    "        output_dir=model_dir,\n",
    "        **train_params\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
